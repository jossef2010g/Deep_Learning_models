{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a36f932-c1cf-4c0f-bd2c-046911e264c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Deep Learning Models for Customer Satisfaction Prediction\n",
    "Implements and compares 6 different deep learning architectures\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, recall_score, precision_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, LSTM, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D,\n",
    "    Embedding, Dropout, Input, concatenate, Attention, MultiHeadAttention,\n",
    "    LayerNormalization, Add, GlobalAveragePooling1D, BatchNormalization, SpatialDropout1D\n",
    ")\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    TerminateOnNaN,\n",
    "    ModelCheckpoint,\n",
    "    CSVLogger\n",
    ")\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6453c4-5664-4f7a-8c0f-6699aa0e9dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Vocab size: 27319\n",
      "Max sequence length: 100\n",
      "Number of features: 14\n",
      "Number of classes: 5\n",
      "Training with balanced data: 19868 samples\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "data = np.load('data/preprocessed_data.npz')\n",
    "\n",
    "X_num_train = data['X_num_train']\n",
    "X_num_val = data['X_num_val']\n",
    "X_num_test = data['X_num_test']\n",
    "X_text_train = data['X_text_train']\n",
    "X_text_val = data['X_text_val']\n",
    "X_text_test = data['X_text_test']\n",
    "X_num_train_balanced = data['X_num_train_balanced']\n",
    "X_text_train_balanced = data['X_text_train_balanced']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n",
    "y_train_balanced = data['y_train_balanced']\n",
    "\n",
    "# Load TF-IDF based data\n",
    "X_train_mlp = data['X_train_mlp']\n",
    "X_val_mlp = data['X_val_mlp']\n",
    "X_test_mlp = data['X_test_mlp']\n",
    "y_train_mlp = data['y_train_mlp']\n",
    "y_val_mlp = data['y_val_mlp']\n",
    "y_test_mlp = data['y_test_mlp']\n",
    "\n",
    "# Load metadata\n",
    "with open('data/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "vocab_size = metadata['vocab_size']\n",
    "max_len = metadata['max_sequence_length']\n",
    "num_features = len(metadata['feature_columns'])\n",
    "num_classes = metadata['num_classes']\n",
    "class_weights = metadata['class_weights']\n",
    "class_names = metadata['class_names']\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Max sequence length: {max_len}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training with balanced data: {X_text_train_balanced.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0828cd3b-034a-489e-9109-064f75d8fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DeepLearningModels:\n",
    "    def __init__(self, vocab_size, max_len, num_features, num_classes, embedding_dim=128):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.models = {}\n",
    "        self.histories = {}\n",
    "\n",
    "    def create_mlp_model(self, input_dim):\n",
    "        \"\"\"Model 6: Deep MLP with TF-IDF features\"\"\"\n",
    "        model = Sequential([ Input(shape=(input_dim,)),\n",
    "                  # First hidden layer with batch normalization\n",
    "                  Dense(1024, activation='relu', kernel_regularizer=l2(0.001), input_shape=(input_dim,)),\n",
    "                  BatchNormalization(),\n",
    "                  Dropout(0.6),\n",
    "                  # Second hidden layer\n",
    "                  Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "                  BatchNormalization(),\n",
    "                  Dropout(0.5),\n",
    "                  # Third hidden layer\n",
    "                  Dense(256, activation='relu'),\n",
    "                  Dropout(0.4),\n",
    "                  Dense(128, activation='relu'),\n",
    "                  # Output layer\n",
    "                  Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def create_lstm_model(self):\n",
    "        \"\"\"Model 1: LSTM-based RNN for sequential text processing\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,))\n",
    "        x = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True)(text_input)\n",
    "        x = SpatialDropout1D(0.3)(x)\n",
    "        x = LSTM(128, return_sequences=True)(x)\n",
    "        x = LSTM(64)(x)\n",
    "\n",
    "        # Numerical input branch\n",
    "        num_input = Input(shape=(self.num_features,))\n",
    "        y = Dense(64, activation='relu')(num_input)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        # Combine branches\n",
    "        z = concatenate([x, y])\n",
    "        z = Dense(128, activation='relu')(z)\n",
    "        z = Dropout(0.5)(z)\n",
    "        output = Dense(self.num_classes, activation='softmax')(z)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        optimizer = Adam(learning_rate=0.001, clipvalue=0.5)\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def create_bilstm_attention_model(self):\n",
    "        \"\"\"Model 2: Bidirectional LSTM with attention mechanism\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,))\n",
    "        x = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True)(text_input)\n",
    "        x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "        # Attention\n",
    "        attention = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "        x = LayerNormalization()(x + attention)\n",
    "\n",
    "        # Numerical branch\n",
    "        num_input = Input(shape=(self.num_features,))\n",
    "        y = Dense(64, activation='swish')(num_input)\n",
    "        y = LayerNormalization()(y)\n",
    "\n",
    "        # Combined\n",
    "        context = GlobalAveragePooling1D()(x)\n",
    "        z = concatenate([context, y])\n",
    "        z = Dense(256, activation='swish')(z)\n",
    "        z = Dropout(0.4)(z)\n",
    "        output = Dense(self.num_classes, activation='softmax')(z)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def create_robust_model(self):\n",
    "        # Text\n",
    "        text_input = Input(shape=(self.max_len,))\n",
    "        x = Embedding(self.vocab_size, 128)(text_input)\n",
    "        x = Bidirectional(LSTM(64))(x)\n",
    "\n",
    "        # Numerical\n",
    "        num_input = Input(shape=(self.num_features,))\n",
    "        y = Dense(64)(num_input)\n",
    "\n",
    "        # Combined\n",
    "        z = concatenate([x, y])\n",
    "        z = Dense(128, activation='relu')(z)\n",
    "        output = Dense(self.num_classes, activation='softmax')(z)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def create_accurate_bilstm_attention_model(self):\n",
    "        \"\"\"High-performance BiLSTM with Attention\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embedding_dim * 2,  # Increased capacity\n",
    "            mask_zero=True\n",
    "        )(text_input)\n",
    "\n",
    "        # Enhanced Bidirectional LSTM\n",
    "        bilstm = Bidirectional(\n",
    "            LSTM(128,  # Doubled units\n",
    "                 dropout=0.3,\n",
    "                 recurrent_dropout=0.25,\n",
    "                 return_sequences=True,\n",
    "                 kernel_regularizer=l2(1e-4))  # Added regularization\n",
    "        )(text_embedding)\n",
    "        bilstm = BatchNormalization()(bilstm)  # Stabilizes training\n",
    "\n",
    "        # Powerful attention mechanism\n",
    "        attention = MultiHeadAttention(\n",
    "            num_heads=8,  # More attention heads\n",
    "            key_dim=128,  # Matches LSTM units\n",
    "            dropout=0.2,\n",
    "            kernel_regularizer=l2(1e-4)\n",
    "        )(bilstm, bilstm)\n",
    "\n",
    "        # Residual connection with layer norm\n",
    "        attention = Add()([bilstm, attention])\n",
    "        attention = LayerNormalization()(attention)\n",
    "\n",
    "        # Context extraction\n",
    "        text_features = GlobalAveragePooling1D()(attention)\n",
    "\n",
    "        # Enhanced numerical branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(num_input)\n",
    "        num_dense = BatchNormalization()(num_dense)\n",
    "\n",
    "        # Feature fusion\n",
    "        combined = concatenate([text_features, num_dense])\n",
    "        combined = Dropout(0.4)(combined)\n",
    "\n",
    "        # Deep classifier head\n",
    "        hidden = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(combined)\n",
    "        hidden = BatchNormalization()(hidden)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        hidden = Dense(128, activation='relu')(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "\n",
    "    def create_cnn_model(self):\n",
    "        \"\"\"Model 3: CNN for text classification with multiple filter sizes\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,))\n",
    "        x = Embedding(self.vocab_size, 128)(text_input)\n",
    "\n",
    "        # Parallel conv branches with residual connections\n",
    "        convs = []\n",
    "        for filter_size in [3, 5, 7]:\n",
    "            conv = Conv1D(128, filter_size, padding='same', activation='relu')(x)\n",
    "            conv = MaxPooling1D(2)(conv)\n",
    "            conv = Conv1D(64, filter_size, padding='same', activation='relu')(conv)\n",
    "            conv = GlobalMaxPooling1D()(conv)\n",
    "            convs.append(conv)\n",
    "\n",
    "        x = concatenate(convs) if len(convs) > 1 else convs[0]\n",
    "\n",
    "        # Numerical branch\n",
    "        num_input = Input(shape=(self.num_features,))\n",
    "        y = Dense(64, activation='relu')(num_input)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        # Combined\n",
    "        z = concatenate([x, y])\n",
    "        z = Dense(128, activation='relu')(z)\n",
    "        z = Dropout(0.5)(z)\n",
    "        output = Dense(self.num_classes, activation='softmax')(z)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        model.compile(optimizer=RMSprop(learning_rate=0.0005),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def create_transformer_model(self):\n",
    "        \"\"\"Model 4: Transformer-based model (simplified BERT-like architecture)\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,))\n",
    "        x = Embedding(self.vocab_size, 128)(text_input)\n",
    "\n",
    "        # Positional encoding\n",
    "        positions = tf.range(start=0, limit=self.max_len, delta=1)\n",
    "        positions = Embedding(self.max_len, 128)(positions)\n",
    "        x = x + positions\n",
    "\n",
    "        # Transformer blocks\n",
    "        for _ in range(3):  # Additional layer\n",
    "            attn = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "            x = LayerNormalization()(x + attn)\n",
    "            ffn = Dense(512, activation='gelu')(x)\n",
    "            ffn = Dense(128)(ffn)\n",
    "            x = LayerNormalization()(x + ffn)\n",
    "\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "        # Numerical branch\n",
    "        num_input = Input(shape=(self.num_features,))\n",
    "        y = Dense(64, activation='relu')(num_input)\n",
    "        y = LayerNormalization()(y)\n",
    "\n",
    "        # Combined\n",
    "        z = concatenate([x, y])\n",
    "        z = Dense(256, activation='gelu')(z)\n",
    "        z = Dropout(0.4)(z)\n",
    "        output = Dense(self.num_classes, activation='softmax')(z)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def create_hybrid_cnn_lstm_model(self):\n",
    "        \"\"\"Model 5: Hybrid CNN-LSTM model\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,))\n",
    "        x = Embedding(self.vocab_size, 128)(text_input)\n",
    "\n",
    "        # CNN part\n",
    "        conv1 = Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "        conv1 = MaxPooling1D(2)(conv1)\n",
    "        conv2 = Conv1D(128, 5, padding='same', activation='relu')(x)\n",
    "        conv2 = MaxPooling1D(2)(conv2)\n",
    "        x = concatenate([conv1, conv2])\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # LSTM part\n",
    "        x = Bidirectional(LSTM(128))(x)\n",
    "\n",
    "        # Numerical branch\n",
    "        num_input = Input(shape=(self.num_features,))\n",
    "        y = Dense(64, activation='relu')(num_input)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        # Combined\n",
    "        z = concatenate([x, y])\n",
    "        z = Dense(256, activation='relu')(z)\n",
    "        z = Dropout(0.5)(z)\n",
    "        output = Dense(self.num_classes, activation='softmax')(z)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def create_hybrid_cnn_lstm_model_modified(self):\n",
    "        \"\"\"Fixed version with all required imports\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(self.vocab_size, self.embedding_dim)(text_input)\n",
    "\n",
    "        # CNN with MaxPooling\n",
    "        conv1 = Conv1D(128, 3, activation='relu', padding='same')(text_embedding)\n",
    "        conv1 = MaxPooling1D(2)(conv1)\n",
    "        conv2 = Conv1D(128, 5, activation='relu', padding='same')(text_embedding)\n",
    "        conv2 = MaxPooling1D(2)(conv2)\n",
    "\n",
    "        conv_combined = concatenate([conv1, conv2])\n",
    "        conv_combined = BatchNormalization()(conv_combined)  # Now properly imported\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(conv_combined)\n",
    "\n",
    "        # Numerical branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu')(num_input)\n",
    "\n",
    "        # Combine branches\n",
    "        combined = concatenate([lstm_out, num_dense])\n",
    "        hidden = Dense(128, activation='relu')(combined)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "\n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "\n",
    "    def compile_model(self, model, learning_rate=0.001):\n",
    "        \"\"\"Compile model with appropriate optimizer and loss function\"\"\"\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def create_callbacks(self):\n",
    "        \"\"\"Create training callbacks\"\"\"\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "\n",
    "        return [early_stopping, reduce_lr]\n",
    "\n",
    "    def train_model_mlp(self, model, model_name, X_train, X_val, y_train, y_val,\n",
    "                    class_weights=None, epochs=100, batch_size=128):\n",
    "        \"\"\"Train a model with given data\"\"\"\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "        #callbacks = self.create_callbacks()\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-5),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        self.models[model_name] = model\n",
    "        self.histories[model_name] = history\n",
    "\n",
    "        return model, history\n",
    "\n",
    "    def train_model(self, model, model_name, X_text_train, X_num_train, y_train,\n",
    "                    X_text_val, X_num_val, y_val, class_weights, epochs=100):\n",
    "        \"\"\"Train a model with given data\"\"\"\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "        callbacks = self.create_callbacks()\n",
    "\n",
    "        history = model.fit(\n",
    "            [X_text_train, X_num_train], y_train,\n",
    "            validation_data=([X_text_val, X_num_val], y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=16,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        self.models[model_name] = model\n",
    "        self.histories[model_name] = history\n",
    "\n",
    "        return model, history\n",
    "\n",
    "    def evaluate_model(self, model, model_name, X_text_test, X_num_test, y_test, class_names):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "\n",
    "        # Make predictions - handle MLP vs other models differently\n",
    "        if 'MLP' in model_name:\n",
    "            # MLP expects single input array\n",
    "            y_pred_proba = model.predict(X_text_test)  # X_text_test actually contains all features for MLP\n",
    "        else:\n",
    "            # Other models expect separate text and numerical inputs\n",
    "            y_pred_proba = model.predict([X_text_test, X_num_test])\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        micro_precision = precision_score(y_test, y_pred, average='micro')\n",
    "        micro_recall = recall_score(y_test, y_pred, average='micro')\n",
    "\n",
    "        # Multi-class ROC AUC\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "        except:\n",
    "            auc_score = 0.0\n",
    "\n",
    "        # Precision, Recall, F1 per class\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'f1_macro': f1_macro,\n",
    "            'auc_score': auc_score,\n",
    "            'micro_precision': micro_precision,\n",
    "            'micro_recall': micro_recall,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_per_class': f1,\n",
    "            'support': support,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm,\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def plot_training_history(self, model_name):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        if model_name not in self.histories:\n",
    "            return\n",
    "\n",
    "        history = self.histories[model_name]\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        # Plot accuracy\n",
    "        ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        ax1.set_title(f'{model_name} - Accuracy')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Accuracy')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Plot loss\n",
    "        ax2.plot(history.history['loss'], label='Training Loss')\n",
    "        ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        ax2.set_title(f'{model_name} - Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'charts/{model_name.lower().replace(\" \", \"_\")}_training_history.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_confusion_matrix(self, results, class_names):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = results['confusion_matrix']\n",
    "        model_name = results['model_name']\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(f'{model_name} - Confusion Matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'charts/{model_name.lower().replace(\" \", \"_\")}_confusion_matrix.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def save_all_models(self, all_results):\n",
    "        \"\"\"Save all trained models with their evaluation results and supporting files for API use\"\"\"\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs('api_models', exist_ok=True)\n",
    "        os.makedirs('api_models/data', exist_ok=True)\n",
    "\n",
    "        # Actual features from your Temu reviews dataset\n",
    "        feature_columns = [\n",
    "            'ReviewCount', 'UserCountry_encoded',\n",
    "            'text_length', 'word_count', 'avg_word_length',\n",
    "            'exclamation_count', 'question_count', 'upper_case_ratio',\n",
    "            'title_text_length', 'title_word_count', 'title_avg_word_length',\n",
    "            'title_exclamation_count', 'title_question_count', 'title_upper_case_ratio'\n",
    "        ]\n",
    "\n",
    "        # Class names based on ReviewRating (1-5 stars)\n",
    "        class_names = [\n",
    "            '1 Star - Very Poor',\n",
    "            '2 Stars - Poor',\n",
    "            '3 Stars - Average',\n",
    "            '4 Stars - Good',\n",
    "            '5 Stars - Excellent'\n",
    "        ]\n",
    "\n",
    "        # Create a package for each model that contains everything needed for serving\n",
    "        for result in all_results:\n",
    "            model_name = result['model_name']\n",
    "            if model_name in self.models:\n",
    "                # Create a directory for this model\n",
    "                model_dir = os.path.join('api_models', model_name.lower().replace(' ', '_'))\n",
    "                os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "                # 1. Save the model in SavedModel format\n",
    "                model_path = os.path.join(model_dir, 'model.keras')\n",
    "                self.models[model_name].save(model_path)\n",
    "\n",
    "                # 2. Save metadata needed for preprocessing\n",
    "                metadata = {\n",
    "                    'max_sequence_length': self.max_len,\n",
    "                    'feature_columns': feature_columns,\n",
    "                    'class_names': class_names,\n",
    "                    'input_details': {\n",
    "                        'text_input': {\n",
    "                            'shape': [None, self.max_len],\n",
    "                            'dtype': 'int32',\n",
    "                            'description': 'Tokenized review text from ReviewText column'\n",
    "                        },\n",
    "                        'numerical_input': {\n",
    "                            'shape': [None, len(feature_columns)],\n",
    "                            'dtype': 'float32',\n",
    "                            'description': f'Numerical features in order: {\", \".join(feature_columns)}'\n",
    "                        }\n",
    "                    },\n",
    "                    'output_details': {\n",
    "                        'description': 'Probability scores for each rating level (1-5 stars)',\n",
    "                        'class_order': class_names\n",
    "                    },\n",
    "                    'data_source': 'temu_reviews_cleaned.csv',\n",
    "                    'text_columns_used': ['ReviewText', 'ReviewTitle'],  # Which text columns were used\n",
    "                    'model_format': 'keras'  # Indicate the saved format\n",
    "                }\n",
    "\n",
    "                with open(os.path.join(model_dir, 'metadata.json'), 'w') as f:\n",
    "                    json.dump(metadata, f, indent=2)\n",
    "\n",
    "                print(f\"✅ Saved API-ready {model_name} package to {model_dir}\")\n",
    "\n",
    "                # Update the result with the path\n",
    "                result['api_model_path'] = model_dir\n",
    "            else:\n",
    "                print(f\"⚠️ Model {model_name} not found in trained models\")\n",
    "\n",
    "        # Save tokenizer if exists\n",
    "        if hasattr(self, 'tokenizer'):\n",
    "            tokenizer_path = os.path.join('api_models', 'tokenizer.pkl')\n",
    "            with open(tokenizer_path, 'wb') as f:\n",
    "                pickle.dump(self.tokenizer, f)\n",
    "            print(f\"✅ Saved tokenizer to {tokenizer_path}\")\n",
    "\n",
    "        # Save complete results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_path = os.path.join('api_models', 'data', f'model_results_{timestamp}.pkl')\n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(all_results, f)\n",
    "\n",
    "        print(f\"\\nAll models saved in API-ready format.\")\n",
    "        print(f\"You can now deploy any model by copying its directory to your API server.\")\n",
    "        return results_path\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4430a1-a52c-495c-8b63-d23d3b97a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training Deep MLP with TF-IDF\n",
      "==================================================\n",
      "\n",
      "Deep MLP with TF-IDF Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">10,255,360</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │      \u001b[38;5;34m10,255,360\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,951,173</span> (41.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,951,173\u001b[0m (41.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,948,101</span> (41.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,948,101\u001b[0m (41.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Deep MLP with TF-IDF...\n",
      "Epoch 1/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 258ms/step - accuracy: 0.3451 - loss: 4.2985 - val_accuracy: 0.5074 - val_loss: 2.9889 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 204ms/step - accuracy: 0.7052 - loss: 2.3900 - val_accuracy: 0.3897 - val_loss: 3.4735 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 297ms/step - accuracy: 0.8014 - loss: 2.0905 - val_accuracy: 0.5022 - val_loss: 3.4328 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 373ms/step - accuracy: 0.8329 - loss: 2.0195 - val_accuracy: 0.5662 - val_loss: 3.0996 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 373ms/step - accuracy: 0.8569 - loss: 1.9327 - val_accuracy: 0.5757 - val_loss: 2.9623 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 133ms/step - accuracy: 0.8616 - loss: 1.8285 - val_accuracy: 0.5750 - val_loss: 2.8377 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 212ms/step - accuracy: 0.8680 - loss: 1.7259 - val_accuracy: 0.6007 - val_loss: 2.7250 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 211ms/step - accuracy: 0.8821 - loss: 1.6259 - val_accuracy: 0.6088 - val_loss: 2.6786 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 207ms/step - accuracy: 0.8745 - loss: 1.5861 - val_accuracy: 0.5706 - val_loss: 2.7858 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 203ms/step - accuracy: 0.8780 - loss: 1.5548 - val_accuracy: 0.5610 - val_loss: 2.7541 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 210ms/step - accuracy: 0.8854 - loss: 1.4990 - val_accuracy: 0.5971 - val_loss: 2.6347 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 205ms/step - accuracy: 0.8909 - loss: 1.3945 - val_accuracy: 0.5478 - val_loss: 2.7147 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 183ms/step - accuracy: 0.8864 - loss: 1.3785 - val_accuracy: 0.6265 - val_loss: 2.4591 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 201ms/step - accuracy: 0.8927 - loss: 1.3461 - val_accuracy: 0.5684 - val_loss: 2.5947 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 181ms/step - accuracy: 0.8912 - loss: 1.3234 - val_accuracy: 0.5868 - val_loss: 2.5146 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 168ms/step - accuracy: 0.8957 - loss: 1.2601 - val_accuracy: 0.5882 - val_loss: 2.5443 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 158ms/step - accuracy: 0.8933 - loss: 1.1959 - val_accuracy: 0.5934 - val_loss: 2.4864 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 151ms/step - accuracy: 0.8901 - loss: 1.2204 - val_accuracy: 0.5551 - val_loss: 2.6303 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 201ms/step - accuracy: 0.8989 - loss: 1.1166 - val_accuracy: 0.5824 - val_loss: 2.4937 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 178ms/step - accuracy: 0.8975 - loss: 1.1130 - val_accuracy: 0.5787 - val_loss: 2.5387 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 202ms/step - accuracy: 0.8968 - loss: 1.1010 - val_accuracy: 0.6309 - val_loss: 2.3289 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 180ms/step - accuracy: 0.9061 - loss: 1.0670 - val_accuracy: 0.6059 - val_loss: 2.3506 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 188ms/step - accuracy: 0.8996 - loss: 1.0351 - val_accuracy: 0.5537 - val_loss: 2.5407 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 200ms/step - accuracy: 0.8954 - loss: 1.0273 - val_accuracy: 0.5882 - val_loss: 2.3631 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 177ms/step - accuracy: 0.9080 - loss: 0.9490 - val_accuracy: 0.5691 - val_loss: 2.4932 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 163ms/step - accuracy: 0.8997 - loss: 0.9698 - val_accuracy: 0.5860 - val_loss: 2.4535 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 153ms/step - accuracy: 0.9120 - loss: 0.9071 - val_accuracy: 0.5809 - val_loss: 2.5731 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 203ms/step - accuracy: 0.9204 - loss: 0.8498 - val_accuracy: 0.6684 - val_loss: 2.2887 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 211ms/step - accuracy: 0.9454 - loss: 0.6603 - val_accuracy: 0.6574 - val_loss: 2.3081 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 214ms/step - accuracy: 0.9446 - loss: 0.5954 - val_accuracy: 0.6559 - val_loss: 2.1865 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 215ms/step - accuracy: 0.9421 - loss: 0.5741 - val_accuracy: 0.6515 - val_loss: 2.3373 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 210ms/step - accuracy: 0.9485 - loss: 0.5357 - val_accuracy: 0.6551 - val_loss: 2.1546 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 217ms/step - accuracy: 0.9481 - loss: 0.5096 - val_accuracy: 0.6522 - val_loss: 2.2470 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 172ms/step - accuracy: 0.9428 - loss: 0.5176 - val_accuracy: 0.6390 - val_loss: 2.2454 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 218ms/step - accuracy: 0.9443 - loss: 0.5105 - val_accuracy: 0.6566 - val_loss: 2.2340 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 135ms/step - accuracy: 0.9440 - loss: 0.5011 - val_accuracy: 0.6603 - val_loss: 2.1015 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 149ms/step - accuracy: 0.9492 - loss: 0.4702 - val_accuracy: 0.6610 - val_loss: 2.2610 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 201ms/step - accuracy: 0.9484 - loss: 0.4822 - val_accuracy: 0.6140 - val_loss: 2.3738 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 178ms/step - accuracy: 0.9502 - loss: 0.4552 - val_accuracy: 0.6375 - val_loss: 2.2276 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 177ms/step - accuracy: 0.9552 - loss: 0.4183 - val_accuracy: 0.6493 - val_loss: 2.3910 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m204/388\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 174ms/step - accuracy: 0.9651 - loss: 0.3608"
     ]
    }
   ],
   "source": [
    "# Define models to train\n",
    "#model_configs = [\n",
    "#    ('Deep MLP with TF-IDF', lambda: model_builder.create_mlp_model(X_train_mlp.shape[1])),\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_robust_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "#]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes, embedding_dim=128)\n",
    "\n",
    "#'Deep MLP with TF-IDF'\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('Deep MLP with TF-IDF', lambda: model_builder.create_mlp_model(X_train_mlp.shape[1]))\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "all_results = []\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    # Special handling for MLP model (uses different data)\n",
    "    if 'MLP' in model_name:\n",
    "        # Handle class imbalance for MLP data\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_mlp_balanced, y_train_mlp_balanced = smote.fit_resample(X_train_mlp, y_train_mlp)\n",
    "\n",
    "        # Train MLP model\n",
    "        model, history = model_builder.train_model_mlp(\n",
    "            model, model_name,\n",
    "            X_train_mlp_balanced, X_val_mlp, y_train_mlp_balanced, y_val_mlp,\n",
    "            class_weights, epochs=50, batch_size=64\n",
    "        )\n",
    "\n",
    "        # Evaluate MLP model\n",
    "        results = model_builder.evaluate_model(\n",
    "            model, model_name, X_test_mlp, None, y_test_mlp, class_names\n",
    "        )\n",
    "    else:\n",
    "        # Train sequence-based models\n",
    "        model, history = model_builder.train_model(\n",
    "            model, model_name,\n",
    "            X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "            X_text_val, X_num_val, y_val,\n",
    "            class_weights, epochs=50\n",
    "        )\n",
    "        # Evaluate model\n",
    "        results = model_builder.evaluate_model(\n",
    "            model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "        )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    print(results.keys())  # Check available keys\n",
    "    print(f\"Micro-averaged precision: {results['micro_precision']:.4f}\")\n",
    "    print(f\"Micro-average recall: {results['micro_recall']:.4f}\")\n",
    "    print(\"Precision:\", \", \".join([f\"{x:.4f}\" for x in results['precision']]))\n",
    "    print(\"Recall:\", \", \".join([f\"{x:.4f}\" for x in results['recall']]))\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92129e1-1a20-434f-86bd-829a1421105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 180ms/step - accuracy: 0.2783 - loss: 2.2227 - val_accuracy: 0.2346 - val_loss: 2.0503 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 191ms/step - accuracy: 0.3971 - loss: 1.8358 - val_accuracy: 0.5243 - val_loss: 1.5521 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 197ms/step - accuracy: 0.5071 - loss: 1.6593 - val_accuracy: 0.4301 - val_loss: 1.7800 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 198ms/step - accuracy: 0.5627 - loss: 1.5420 - val_accuracy: 0.5162 - val_loss: 1.7360 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 189ms/step - accuracy: 0.6088 - loss: 1.4218 - val_accuracy: 0.5184 - val_loss: 1.7840 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 172ms/step - accuracy: 0.6302 - loss: 1.3170 - val_accuracy: 0.5243 - val_loss: 1.7457 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 169ms/step - accuracy: 0.6648 - loss: 1.1947 - val_accuracy: 0.5353 - val_loss: 1.9369 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 181ms/step - accuracy: 0.7011 - loss: 1.0752 - val_accuracy: 0.5654 - val_loss: 1.9949 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 195ms/step - accuracy: 0.7290 - loss: 0.9370 - val_accuracy: 0.5831 - val_loss: 1.9717 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 198ms/step - accuracy: 0.7598 - loss: 0.8047 - val_accuracy: 0.5816 - val_loss: 1.9697 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 159ms/step - accuracy: 0.7890 - loss: 0.6847 - val_accuracy: 0.5860 - val_loss: 2.0687 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 171ms/step - accuracy: 0.8006 - loss: 0.6034 - val_accuracy: 0.6132 - val_loss: 2.1032 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 189ms/step - accuracy: 0.8193 - loss: 0.5583 - val_accuracy: 0.6147 - val_loss: 2.2638 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 170ms/step - accuracy: 0.8306 - loss: 0.4949 - val_accuracy: 0.5816 - val_loss: 2.4202 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 166ms/step - accuracy: 0.8377 - loss: 0.4594 - val_accuracy: 0.6000 - val_loss: 2.4099 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 222ms/step - accuracy: 0.8558 - loss: 0.3985 - val_accuracy: 0.6309 - val_loss: 2.4218 - learning_rate: 2.5000e-04\n",
      "\n",
      "Evaluating LSTM Model...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step\n",
      "\n",
      "LSTM Model Results:\n",
      "Accuracy: 0.5094\n",
      "F1-Score (Weighted): 0.5776\n",
      "F1-Score (Macro): 0.3517\n",
      "AUC Score: 0.8754\n"
     ]
    }
   ],
   "source": [
    "#model_configs = [\n",
    "#    ('Deep MLP with TF-IDF', lambda: model_builder.create_mlp_model(X_train_mlp.shape[1])),\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_robust_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "#]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'BiLSTM with Attention', model_builder.create_bilstm_attention_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('LSTM Model', model_builder.create_lstm_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91acc43-c07e-429b-accc-4d9be54efa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training BiLSTM with Attention\n",
      "==================================================\n",
      "\n",
      "BiLSTM with Attention Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,496,832</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                               │                           │                 │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m3,496,832\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m960\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                               │                           │                 │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m24,704\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m645\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,621,957</span> (13.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,621,957\u001b[0m (13.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,621,957</span> (13.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,621,957\u001b[0m (13.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training BiLSTM with Attention...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 72ms/step - accuracy: 0.3171 - loss: 2.0375 - val_accuracy: 0.4250 - val_loss: 1.8026 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 101ms/step - accuracy: 0.6201 - loss: 1.3534 - val_accuracy: 0.4206 - val_loss: 2.0618 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 98ms/step - accuracy: 0.6847 - loss: 1.0949 - val_accuracy: 0.5029 - val_loss: 1.8362 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 97ms/step - accuracy: 0.7383 - loss: 0.8558 - val_accuracy: 0.5463 - val_loss: 1.8579 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 104ms/step - accuracy: 0.7761 - loss: 0.6987 - val_accuracy: 0.6074 - val_loss: 1.8134 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 105ms/step - accuracy: 0.8337 - loss: 0.4798 - val_accuracy: 0.5831 - val_loss: 2.3132 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 107ms/step - accuracy: 0.8594 - loss: 0.3907 - val_accuracy: 0.5699 - val_loss: 2.5963 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1769s\u001b[0m 1s/step - accuracy: 0.9085 - loss: 0.2270 - val_accuracy: 0.6154 - val_loss: 2.6806 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 110ms/step - accuracy: 0.9349 - loss: 0.1583 - val_accuracy: 0.6169 - val_loss: 3.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 111ms/step - accuracy: 0.9538 - loss: 0.1154 - val_accuracy: 0.6235 - val_loss: 3.1816 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 111ms/step - accuracy: 0.9519 - loss: 0.1201 - val_accuracy: 0.6206 - val_loss: 3.4311 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 110ms/step - accuracy: 0.9619 - loss: 0.0962 - val_accuracy: 0.6096 - val_loss: 3.6408 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 112ms/step - accuracy: 0.9767 - loss: 0.0579 - val_accuracy: 0.6118 - val_loss: 3.9297 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 111ms/step - accuracy: 0.9828 - loss: 0.0445 - val_accuracy: 0.6368 - val_loss: 4.0812 - learning_rate: 2.5000e-04\n",
      "\n",
      "Evaluating BiLSTM with Attention...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step\n",
      "\n",
      "BiLSTM with Attention Results:\n",
      "Accuracy: 0.4546\n",
      "F1-Score (Weighted): 0.5240\n",
      "F1-Score (Macro): 0.3190\n",
      "AUC Score: 0.8515\n"
     ]
    }
   ],
   "source": [
    "#model_configs = [\n",
    "#    ('Deep MLP with TF-IDF', lambda: model_builder.create_mlp_model(X_train_mlp.shape[1])),\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_robust_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "#]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'CNN Model', model_builder.create_cnn_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('BiLSTM with Attention', model_builder.create_robust_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9ff112-9ab0-4497-936a-bf313fd1b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training CNN Model\n",
      "==================================================\n",
      "\n",
      "CNN Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,496,832</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">57,408</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ global_max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ global_max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                               │                           │                 │ batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m3,496,832\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m49,280\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m82,048\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │         \u001b[38;5;34m114,816\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m24,640\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m41,024\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m57,408\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m960\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ global_max_pooling1d_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ global_max_pooling1d_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                               │                           │                 │ batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m645\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,900,805</span> (14.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,900,805\u001b[0m (14.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,900,677</span> (14.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,900,677\u001b[0m (14.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN Model...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 91ms/step - accuracy: 0.2800 - loss: 2.2053 - val_accuracy: 0.1029 - val_loss: 2.4103 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 88ms/step - accuracy: 0.5401 - loss: 1.5624 - val_accuracy: 0.5596 - val_loss: 1.5740 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 88ms/step - accuracy: 0.7185 - loss: 0.9241 - val_accuracy: 0.5507 - val_loss: 1.8061 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 80ms/step - accuracy: 0.7706 - loss: 0.7001 - val_accuracy: 0.5537 - val_loss: 1.8578 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 85ms/step - accuracy: 0.7978 - loss: 0.6015 - val_accuracy: 0.5912 - val_loss: 1.7768 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 75ms/step - accuracy: 0.8203 - loss: 0.5176 - val_accuracy: 0.6118 - val_loss: 1.9188 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 84ms/step - accuracy: 0.8450 - loss: 0.4512 - val_accuracy: 0.5279 - val_loss: 2.6624 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 82ms/step - accuracy: 0.8608 - loss: 0.3967 - val_accuracy: 0.5779 - val_loss: 2.5040 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 78ms/step - accuracy: 0.8905 - loss: 0.3167 - val_accuracy: 0.6551 - val_loss: 2.4755 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 96ms/step - accuracy: 0.9302 - loss: 0.1670 - val_accuracy: 0.6618 - val_loss: 2.9578 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 74ms/step - accuracy: 0.9597 - loss: 0.0974 - val_accuracy: 0.6382 - val_loss: 3.1863 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 93ms/step - accuracy: 0.9679 - loss: 0.0798 - val_accuracy: 0.5904 - val_loss: 3.6308 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 97ms/step - accuracy: 0.9765 - loss: 0.0560 - val_accuracy: 0.6191 - val_loss: 3.7243 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 81ms/step - accuracy: 0.9764 - loss: 0.0633 - val_accuracy: 0.5919 - val_loss: 3.7803 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 90ms/step - accuracy: 0.9776 - loss: 0.0633 - val_accuracy: 0.6728 - val_loss: 3.8756 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 93ms/step - accuracy: 0.9863 - loss: 0.0389 - val_accuracy: 0.6610 - val_loss: 4.2561 - learning_rate: 2.5000e-04\n",
      "\n",
      "Evaluating CNN Model...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step\n",
      "\n",
      "CNN Model Results:\n",
      "Accuracy: 0.5337\n",
      "F1-Score (Weighted): 0.5904\n",
      "F1-Score (Macro): 0.3456\n",
      "AUC Score: 0.8626\n"
     ]
    }
   ],
   "source": [
    "#model_configs = [\n",
    "#    ('Deep MLP with TF-IDF', lambda: model_builder.create_mlp_model(X_train_mlp.shape[1])),\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_robust_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "#]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'Transformer Model', model_builder.create_transformer_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('CNN Model', model_builder.create_cnn_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8179cb7-404c-405d-8679-9122bd68afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training Transformer Model\n",
      "==================================================\n",
      "\n",
      "Transformer Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,496,832</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                 │\n",
       "│                               │                           │                 │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                               │                           │                 │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ multi_head_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ multi_head_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m3,496,832\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m66,048\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                 │\n",
       "│                               │                           │                 │ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │          \u001b[38;5;34m66,048\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m65,664\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                               │                           │                 │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m66,048\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ multi_head_attention_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │          \u001b[38;5;34m66,048\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m65,664\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m66,048\u001b[0m │ layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ multi_head_attention_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │          \u001b[38;5;34m66,048\u001b[0m │ layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m65,664\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m960\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_4 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ global_average_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │          \u001b[38;5;34m49,408\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │           \u001b[38;5;34m1,285\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,143,429</span> (15.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,143,429\u001b[0m (15.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,143,429</span> (15.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,143,429\u001b[0m (15.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Transformer Model...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 291ms/step - accuracy: 0.2895 - loss: 2.1586 - val_accuracy: 0.0941 - val_loss: 2.4799 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 285ms/step - accuracy: 0.3401 - loss: 1.9044 - val_accuracy: 0.1250 - val_loss: 2.4028 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 287ms/step - accuracy: 0.3662 - loss: 1.8333 - val_accuracy: 0.1140 - val_loss: 2.5543 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 275ms/step - accuracy: 0.3708 - loss: 1.8128 - val_accuracy: 0.1199 - val_loss: 2.4856 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 287ms/step - accuracy: 0.4011 - loss: 1.7055 - val_accuracy: 0.1382 - val_loss: 2.4695 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 300ms/step - accuracy: 0.4147 - loss: 1.6487 - val_accuracy: 0.1382 - val_loss: 2.4450 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 326ms/step - accuracy: 0.4346 - loss: 1.5624 - val_accuracy: 0.1500 - val_loss: 2.4228 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 330ms/step - accuracy: 0.4535 - loss: 1.5007 - val_accuracy: 0.1493 - val_loss: 2.4038 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 335ms/step - accuracy: 0.4654 - loss: 1.4572 - val_accuracy: 0.1574 - val_loss: 2.4468 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 350ms/step - accuracy: 0.4860 - loss: 1.3562 - val_accuracy: 0.1706 - val_loss: 2.4157 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 356ms/step - accuracy: 0.5068 - loss: 1.2817 - val_accuracy: 0.1735 - val_loss: 2.4374 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 365ms/step - accuracy: 0.5086 - loss: 1.2589 - val_accuracy: 0.1809 - val_loss: 2.4128 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 365ms/step - accuracy: 0.5231 - loss: 1.2216 - val_accuracy: 0.1941 - val_loss: 2.4118 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 378ms/step - accuracy: 0.5328 - loss: 1.1839 - val_accuracy: 0.1904 - val_loss: 2.4199 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 363ms/step - accuracy: 0.5360 - loss: 1.1665 - val_accuracy: 0.2029 - val_loss: 2.3898 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 350ms/step - accuracy: 0.5458 - loss: 1.1297 - val_accuracy: 0.2110 - val_loss: 2.4202 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 349ms/step - accuracy: 0.5493 - loss: 1.1046 - val_accuracy: 0.2015 - val_loss: 2.4377 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 321ms/step - accuracy: 0.5481 - loss: 1.1063 - val_accuracy: 0.2110 - val_loss: 2.4577 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 354ms/step - accuracy: 0.5580 - loss: 1.0898 - val_accuracy: 0.2184 - val_loss: 2.4493 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 301ms/step - accuracy: 0.5661 - loss: 1.0511 - val_accuracy: 0.2162 - val_loss: 2.5338 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 327ms/step - accuracy: 0.5673 - loss: 1.0281 - val_accuracy: 0.2353 - val_loss: 2.4823 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 322ms/step - accuracy: 0.5760 - loss: 1.0150 - val_accuracy: 0.2382 - val_loss: 2.4885 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 318ms/step - accuracy: 0.5819 - loss: 0.9572 - val_accuracy: 0.2338 - val_loss: 2.4725 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 367ms/step - accuracy: 0.5860 - loss: 0.9467 - val_accuracy: 0.2375 - val_loss: 2.4883 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 325ms/step - accuracy: 0.5906 - loss: 0.9393 - val_accuracy: 0.2390 - val_loss: 2.5154 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 341ms/step - accuracy: 0.5923 - loss: 0.9166 - val_accuracy: 0.2471 - val_loss: 2.4955 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 325ms/step - accuracy: 0.5985 - loss: 0.9132 - val_accuracy: 0.2463 - val_loss: 2.5387 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 255ms/step - accuracy: 0.5996 - loss: 0.9011 - val_accuracy: 0.2390 - val_loss: 2.5355 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 180ms/step - accuracy: 0.6102 - loss: 0.8785 - val_accuracy: 0.2434 - val_loss: 2.5345 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 180ms/step - accuracy: 0.6047 - loss: 0.8829 - val_accuracy: 0.2434 - val_loss: 2.5304 - learning_rate: 1.2500e-04\n",
      "\n",
      "Evaluating Transformer Model...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step\n",
      "\n",
      "Transformer Model Results:\n",
      "Accuracy: 0.2041\n",
      "F1-Score (Weighted): 0.2376\n",
      "F1-Score (Macro): 0.1615\n",
      "AUC Score: 0.5741\n"
     ]
    }
   ],
   "source": [
    "#model_configs = [\n",
    "#    ('Deep MLP with TF-IDF', lambda: model_builder.create_mlp_model(X_train_mlp.shape[1])),\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_robust_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "#]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('Transformer Model', model_builder.create_transformer_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b572b4-e566-4642-b077-11db5818d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training Hybrid CNN-LSTM\n",
      "==================================================\n",
      "\n",
      "Hybrid CNN-LSTM Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,496,832</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_4               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                               │                           │                 │ max_pooling1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ batch_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                               │                           │                 │ batch_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m3,496,832\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m49,280\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m82,048\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_4               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_5 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                               │                           │                 │ max_pooling1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m960\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m394,240\u001b[0m │ batch_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_6 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                               │                           │                 │ batch_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │          \u001b[38;5;34m82,176\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │           \u001b[38;5;34m1,285\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,108,101</span> (15.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,108,101\u001b[0m (15.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,107,461</span> (15.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,107,461\u001b[0m (15.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Hybrid CNN-LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 80ms/step - accuracy: 0.3014 - loss: 2.1519 - val_accuracy: 0.3985 - val_loss: 1.8427 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 81ms/step - accuracy: 0.4753 - loss: 1.7171 - val_accuracy: 0.4824 - val_loss: 1.6117 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 81ms/step - accuracy: 0.5906 - loss: 1.4349 - val_accuracy: 0.5132 - val_loss: 1.7146 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 81ms/step - accuracy: 0.6751 - loss: 1.1104 - val_accuracy: 0.5184 - val_loss: 1.7820 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 81ms/step - accuracy: 0.7401 - loss: 0.8324 - val_accuracy: 0.5184 - val_loss: 2.0323 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 82ms/step - accuracy: 0.7833 - loss: 0.6461 - val_accuracy: 0.6103 - val_loss: 1.8043 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 81ms/step - accuracy: 0.8239 - loss: 0.4968 - val_accuracy: 0.5941 - val_loss: 2.0346 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 82ms/step - accuracy: 0.8526 - loss: 0.4265 - val_accuracy: 0.6125 - val_loss: 2.1704 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 82ms/step - accuracy: 0.8713 - loss: 0.3700 - val_accuracy: 0.5985 - val_loss: 2.4979 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 82ms/step - accuracy: 0.8987 - loss: 0.2610 - val_accuracy: 0.6404 - val_loss: 2.7140 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 82ms/step - accuracy: 0.9496 - loss: 0.1152 - val_accuracy: 0.6346 - val_loss: 3.1651 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 83ms/step - accuracy: 0.9734 - loss: 0.0636 - val_accuracy: 0.6346 - val_loss: 3.5486 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 83ms/step - accuracy: 0.9757 - loss: 0.0579 - val_accuracy: 0.6456 - val_loss: 3.7633 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 83ms/step - accuracy: 0.9729 - loss: 0.0726 - val_accuracy: 0.6088 - val_loss: 4.2100 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 83ms/step - accuracy: 0.9783 - loss: 0.0529 - val_accuracy: 0.6066 - val_loss: 4.1271 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 83ms/step - accuracy: 0.9797 - loss: 0.0612 - val_accuracy: 0.6456 - val_loss: 4.0814 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 83ms/step - accuracy: 0.9876 - loss: 0.0377 - val_accuracy: 0.6235 - val_loss: 4.4708 - learning_rate: 2.5000e-04\n",
      "\n",
      "Evaluating Hybrid CNN-LSTM...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step\n",
      "\n",
      "Hybrid CNN-LSTM Results:\n",
      "Accuracy: 0.4678\n",
      "F1-Score (Weighted): 0.5441\n",
      "F1-Score (Macro): 0.3173\n",
      "AUC Score: 0.8453\n"
     ]
    }
   ],
   "source": [
    "#model_configs = [\n",
    "#    ('Deep MLP with TF-IDF', lambda: model_builder.create_mlp_model(X_train_mlp.shape[1])),\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_robust_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "#]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1f634f-6aaa-4bf5-9101-d83186bd9888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model_name': 'Deep MLP with TF-IDF', 'accuracy': 0.6609047443913203, 'f1_weighted': 0.6850760177709129, 'f1_macro': 0.43772467048663505, 'auc_score': np.float64(0.8637367863754088), 'micro_precision': 0.6609047443913203, 'micro_recall': 0.6609047443913203, 'precision': array([0.87340764, 0.18503937, 0.11711712, 0.22779923, 0.78021978]), 'recall': array([0.77471751, 0.27647059, 0.20155039, 0.26818182, 0.7244898 ]), 'f1_per_class': array([0.82110778, 0.22169811, 0.14814815, 0.24634656, 0.75132275]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.8734076433121019, 'recall': 0.7747175141242938, 'f1-score': 0.8211077844311377, 'support': 1416.0}, 'Rating 2': {'precision': 0.18503937007874016, 'recall': 0.27647058823529413, 'f1-score': 0.22169811320754718, 'support': 170.0}, 'Rating 3': {'precision': 0.11711711711711711, 'recall': 0.20155038759689922, 'f1-score': 0.14814814814814814, 'support': 129.0}, 'Rating 4': {'precision': 0.2277992277992278, 'recall': 0.2681818181818182, 'f1-score': 0.24634655532359082, 'support': 220.0}, 'Rating 5': {'precision': 0.7802197802197802, 'recall': 0.7244897959183674, 'f1-score': 0.7513227513227513, 'support': 784.0}, 'accuracy': 0.6609047443913203, 'macro avg': {'precision': 0.4367166277053934, 'recall': 0.4490820208113345, 'f1-score': 0.43772467048663505, 'support': 2719.0}, 'weighted avg': {'precision': 0.7153799785802015, 'recall': 0.6609047443913203, 'f1-score': 0.6850760177709129, 'support': 2719.0}}, 'confusion_matrix': array([[1097,  142,  108,   44,   25],\n",
      "       [  72,   47,   24,   16,   11],\n",
      "       [  33,   25,   26,   24,   21],\n",
      "       [  23,   14,   21,   59,  103],\n",
      "       [  31,   26,   43,  116,  568]]), 'y_pred': array([3, 1, 1, ..., 0, 0, 4], shape=(2719,)), 'y_pred_proba': array([[1.9976879e-03, 1.0550228e-02, 2.1064012e-04, 8.9769560e-01,\n",
      "        8.9545831e-02],\n",
      "       [2.9991090e-01, 6.6544110e-01, 2.5794514e-02, 1.1449059e-03,\n",
      "        7.7085332e-03],\n",
      "       [2.8179616e-02, 9.6998388e-01, 6.2849787e-05, 8.3201512e-06,\n",
      "        1.7652980e-03],\n",
      "       ...,\n",
      "       [9.9959451e-01, 2.0832222e-04, 1.8279172e-05, 9.2996179e-06,\n",
      "        1.6966337e-04],\n",
      "       [9.8847896e-01, 2.3991615e-03, 3.3082295e-04, 6.6334028e-03,\n",
      "        2.1577436e-03],\n",
      "       [6.0274644e-05, 8.5654179e-08, 6.5362009e-09, 1.2189823e-06,\n",
      "        9.9993837e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'LSTM Model', 'accuracy': 0.5093784479588084, 'f1_weighted': 0.5776389483986392, 'f1_macro': 0.351721969822451, 'auc_score': np.float64(0.8754086414128001), 'micro_precision': 0.5093784479588084, 'micro_recall': 0.5093784479588084, 'precision': array([0.92035398, 0.        , 0.07373272, 0.19047619, 0.8015625 ]), 'recall': array([0.51412429, 0.        , 0.49612403, 0.36363636, 0.65433673]), 'f1_per_class': array([0.65971908, 0.        , 0.12838516, 0.25      , 0.72050562]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.9203539823008849, 'recall': 0.5141242937853108, 'f1-score': 0.659719075668328, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.07373271889400922, 'recall': 0.49612403100775193, 'f1-score': 0.1283851554663992, 'support': 129.0}, 'Rating 4': {'precision': 0.19047619047619047, 'recall': 0.36363636363636365, 'f1-score': 0.25, 'support': 220.0}, 'Rating 5': {'precision': 0.8015625, 'recall': 0.6543367346938775, 'f1-score': 0.7205056179775281, 'support': 784.0}, 'accuracy': 0.5093784479588084, 'macro avg': {'precision': 0.39722507833421694, 'recall': 0.40564428462466073, 'f1-score': 0.351721969822451, 'support': 2719.0}, 'weighted avg': {'precision': 0.729335241478537, 'recall': 0.5093784479588084, 'f1-score': 0.5776389483986392, 'support': 2719.0}}, 'confusion_matrix': array([[728,   0, 570,  91,  27],\n",
      "       [ 30,   0, 107,  28,   5],\n",
      "       [ 16,   0,  64,  34,  15],\n",
      "       [  6,   0,  54,  80,  80],\n",
      "       [ 11,   0,  73, 187, 513]]), 'y_pred': array([3, 2, 2, ..., 0, 2, 4], shape=(2719,)), 'y_pred_proba': array([[5.0557419e-03, 4.4658999e-03, 5.1797684e-02, 7.4601901e-01,\n",
      "        1.9266163e-01],\n",
      "       [8.9264371e-02, 5.3388701e-04, 8.8496685e-01, 2.2240203e-02,\n",
      "        2.9946219e-03],\n",
      "       [3.8265474e-03, 7.6819299e-04, 6.4907038e-01, 3.0565161e-01,\n",
      "        4.0683299e-02],\n",
      "       ...,\n",
      "       [5.8915830e-01, 1.9768931e-03, 3.4472200e-01, 5.5397555e-02,\n",
      "        8.7453136e-03],\n",
      "       [2.1055566e-01, 5.6482475e-02, 3.7856197e-01, 2.1378717e-01,\n",
      "        1.4061277e-01],\n",
      "       [3.5501225e-04, 6.1782499e-05, 3.1132505e-03, 2.4952386e-01,\n",
      "        7.4694616e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'BiLSTM with Attention', 'accuracy': 0.45457888929753587, 'f1_weighted': 0.5239628241568305, 'f1_macro': 0.3189931373706242, 'auc_score': np.float64(0.8514595596614168), 'micro_precision': 0.45457888929753587, 'micro_recall': 0.45457888929753587, 'precision': array([0.9203125 , 0.        , 0.0625711 , 0.14638783, 0.76409496]), 'recall': array([0.41596045, 0.        , 0.42635659, 0.35      , 0.65688776]), 'f1_per_class': array([0.5729572 , 0.        , 0.10912698, 0.20643432, 0.70644719]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.9203125, 'recall': 0.4159604519774011, 'f1-score': 0.5729571984435797, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.06257110352673492, 'recall': 0.4263565891472868, 'f1-score': 0.10912698412698413, 'support': 129.0}, 'Rating 4': {'precision': 0.14638783269961977, 'recall': 0.35, 'f1-score': 0.2064343163538874, 'support': 220.0}, 'Rating 5': {'precision': 0.7640949554896143, 'recall': 0.6568877551020408, 'f1-score': 0.7064471879286695, 'support': 784.0}, 'accuracy': 0.45457888929753587, 'macro avg': {'precision': 0.37867327834319375, 'recall': 0.36984095924534566, 'f1-score': 0.3189931373706242, 'support': 2719.0}, 'weighted avg': {'precision': 0.7144133654478568, 'recall': 0.45457888929753587, 'f1-score': 0.5239628241568305, 'support': 2719.0}}, 'confusion_matrix': array([[589,   0, 621, 169,  37],\n",
      "       [ 27,   0,  95,  39,   9],\n",
      "       [  9,   0,  55,  44,  21],\n",
      "       [  7,   0,  44,  77,  92],\n",
      "       [  8,   0,  64, 197, 515]]), 'y_pred': array([3, 2, 2, ..., 2, 2, 4], shape=(2719,)), 'y_pred_proba': array([[3.5861277e-03, 1.2174087e-04, 7.1513824e-02, 7.7412736e-01,\n",
      "        1.5065101e-01],\n",
      "       [9.2358716e-02, 1.5802552e-03, 8.9651966e-01, 5.9488649e-04,\n",
      "        8.9464961e-03],\n",
      "       [3.5312101e-03, 8.3154044e-04, 8.8754129e-01, 9.6267104e-02,\n",
      "        1.1828821e-02],\n",
      "       ...,\n",
      "       [2.7624886e-02, 4.3241077e-04, 7.9582030e-01, 1.4496954e-01,\n",
      "        3.1152943e-02],\n",
      "       [2.8227073e-01, 1.2207922e-02, 3.2240444e-01, 2.7127612e-01,\n",
      "        1.1184083e-01],\n",
      "       [2.3296960e-03, 4.7329166e-05, 2.2503848e-03, 1.1920222e-01,\n",
      "        8.7617034e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'CNN Model', 'accuracy': 0.5336520779698418, 'f1_weighted': 0.5904320661639688, 'f1_macro': 0.3455835106583427, 'auc_score': np.float64(0.8625956708811896), 'micro_precision': 0.5336520779698418, 'micro_recall': 0.5336520779698418, 'precision': array([0.90690033, 0.        , 0.08466819, 0.13091922, 0.75576037]), 'recall': array([0.58474576, 0.        , 0.28682171, 0.42727273, 0.62755102]), 'f1_per_class': array([0.71103478, 0.        , 0.13074205, 0.20042644, 0.68571429]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.9069003285870756, 'recall': 0.5847457627118644, 'f1-score': 0.7110347788750536, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.08466819221967964, 'recall': 0.2868217054263566, 'f1-score': 0.13074204946996468, 'support': 129.0}, 'Rating 4': {'precision': 0.1309192200557103, 'recall': 0.42727272727272725, 'f1-score': 0.20042643923240938, 'support': 220.0}, 'Rating 5': {'precision': 0.7557603686635944, 'recall': 0.6275510204081632, 'f1-score': 0.6857142857142857, 'support': 784.0}, 'accuracy': 0.5336520779698418, 'macro avg': {'precision': 0.375649621905212, 'recall': 0.3852782431638223, 'f1-score': 0.3455835106583427, 'support': 2719.0}, 'weighted avg': {'precision': 0.7048221476719941, 'recall': 0.5336520779698418, 'f1-score': 0.5904320661639688, 'support': 2719.0}}, 'confusion_matrix': array([[828,   0, 277, 261,  50],\n",
      "       [ 47,   0,  48,  62,  13],\n",
      "       [ 19,   0,  37,  61,  12],\n",
      "       [  7,   0,  35,  94,  84],\n",
      "       [ 12,   0,  40, 240, 492]]), 'y_pred': array([3, 2, 2, ..., 0, 3, 4], shape=(2719,)), 'y_pred_proba': array([[4.5886091e-03, 3.8643219e-03, 4.8785299e-02, 8.8378108e-01,\n",
      "        5.8980718e-02],\n",
      "       [1.9605687e-01, 7.9421984e-04, 7.3452008e-01, 4.0308204e-02,\n",
      "        2.8320648e-02],\n",
      "       [4.6293225e-04, 9.0942949e-06, 9.4585240e-01, 5.1792473e-02,\n",
      "        1.8830021e-03],\n",
      "       ...,\n",
      "       [5.8201778e-01, 2.1412319e-03, 3.0538976e-01, 9.5441371e-02,\n",
      "        1.5009883e-02],\n",
      "       [7.0481021e-03, 6.6980729e-03, 6.7953467e-02, 5.8155471e-01,\n",
      "        3.3674568e-01],\n",
      "       [1.8820215e-07, 1.3289414e-08, 2.1657813e-06, 8.9967251e-03,\n",
      "        9.9100095e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'Transformer Model', 'accuracy': 0.2041191614564178, 'f1_weighted': 0.2376098281526462, 'f1_macro': 0.1614903350046531, 'auc_score': np.float64(0.5741225960950126), 'micro_precision': 0.2041191614564178, 'micro_recall': 0.2041191614564178, 'precision': array([0.74038462, 0.        , 0.06080347, 0.09229305, 0.39400922]), 'recall': array([0.16313559, 0.        , 0.43410853, 0.44090909, 0.21811224]), 'f1_per_class': array([0.26736111, 0.        , 0.10666667, 0.15263572, 0.28078818]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.7403846153846154, 'recall': 0.163135593220339, 'f1-score': 0.2673611111111111, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.06080347448425624, 'recall': 0.43410852713178294, 'f1-score': 0.10666666666666667, 'support': 129.0}, 'Rating 4': {'precision': 0.0922930542340628, 'recall': 0.4409090909090909, 'f1-score': 0.15263571990558616, 'support': 220.0}, 'Rating 5': {'precision': 0.39400921658986177, 'recall': 0.2181122448979592, 'f1-score': 0.28078817733990147, 'support': 784.0}, 'accuracy': 0.2041191614564178, 'macro avg': {'precision': 0.25749807213855924, 'recall': 0.25125309123183437, 'f1-score': 0.1614903350046531, 'support': 2719.0}, 'weighted avg': {'precision': 0.5095387868080287, 'recall': 0.2041191614564178, 'f1-score': 0.2376098281526462, 'support': 2719.0}}, 'confusion_matrix': array([[231,   0, 494, 496, 195],\n",
      "       [ 19,   0,  56,  74,  21],\n",
      "       [  7,   0,  56,  53,  13],\n",
      "       [ 12,   0,  77,  97,  34],\n",
      "       [ 43,   1, 238, 331, 171]]), 'y_pred': array([3, 0, 2, ..., 2, 4, 3], shape=(2719,)), 'y_pred_proba': array([[5.0408807e-02, 1.7219568e-04, 3.6491588e-02, 8.6183333e-01,\n",
      "        5.1094145e-02],\n",
      "       [9.3323284e-01, 1.1924207e-05, 5.0024658e-02, 8.5838210e-06,\n",
      "        1.6722035e-02],\n",
      "       [2.8598377e-02, 3.5623056e-04, 7.4241680e-01, 1.6335957e-01,\n",
      "        6.5269031e-02],\n",
      "       ...,\n",
      "       [2.3571255e-02, 6.8190406e-05, 7.6252609e-01, 1.7282252e-01,\n",
      "        4.1011959e-02],\n",
      "       [2.5102863e-01, 6.3161133e-04, 7.1365558e-02, 8.1266746e-02,\n",
      "        5.9570748e-01],\n",
      "       [6.8447933e-02, 3.7536132e-03, 5.9464546e-03, 7.2965127e-01,\n",
      "        1.9220072e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'Hybrid CNN-LSTM', 'accuracy': 0.46781905112173594, 'f1_weighted': 0.54405282013401, 'f1_macro': 0.31727327414145545, 'auc_score': np.float64(0.8452530334888564), 'micro_precision': 0.46781905112173594, 'micro_recall': 0.46781905112173594, 'precision': array([0.89192399, 0.        , 0.0651341 , 0.13464696, 0.8       ]), 'recall': array([0.53036723, 0.        , 0.39534884, 0.37272727, 0.49489796]), 'f1_per_class': array([0.66519043, 0.        , 0.11184211, 0.19782871, 0.61150512]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.8919239904988123, 'recall': 0.530367231638418, 'f1-score': 0.6651904340124003, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.06513409961685823, 'recall': 0.3953488372093023, 'f1-score': 0.1118421052631579, 'support': 129.0}, 'Rating 4': {'precision': 0.13464696223316913, 'recall': 0.37272727272727274, 'f1-score': 0.19782870928829915, 'support': 220.0}, 'Rating 5': {'precision': 0.8, 'recall': 0.49489795918367346, 'f1-score': 0.61150512214342, 'support': 784.0}, 'accuracy': 0.46781905112173594, 'macro avg': {'precision': 0.3783410104697679, 'recall': 0.35866826015173336, 'f1-score': 0.31727327414145545, 'support': 2719.0}, 'weighted avg': {'precision': 0.7091537333902869, 'recall': 0.46781905112173594, 'f1-score': 0.54405282013401, 'support': 2719.0}}, 'confusion_matrix': array([[751,   0, 514, 132,  19],\n",
      "       [ 45,   0,  78,  42,   5],\n",
      "       [ 20,   0,  51,  48,  10],\n",
      "       [ 14,   0,  61,  82,  63],\n",
      "       [ 12,   0,  79, 305, 388]]), 'y_pred': array([3, 0, 2, ..., 2, 3, 4], shape=(2719,)), 'y_pred_proba': array([[2.72521493e-03, 4.01473633e-04, 1.80531189e-01, 7.15884447e-01,\n",
      "        1.00457646e-01],\n",
      "       [6.24789000e-01, 4.55124391e-05, 3.67165327e-01, 4.47264081e-03,\n",
      "        3.52748018e-03],\n",
      "       [9.95961800e-02, 1.11094350e-03, 8.42113197e-01, 4.95583713e-02,\n",
      "        7.62132881e-03],\n",
      "       ...,\n",
      "       [3.23541164e-01, 7.79318565e-04, 6.35169923e-01, 2.58344151e-02,\n",
      "        1.46751488e-02],\n",
      "       [3.44536528e-02, 4.15411964e-03, 1.85468197e-01, 4.54515010e-01,\n",
      "        3.21409047e-01],\n",
      "       [4.38457029e-03, 3.33657634e-04, 1.48983411e-02, 1.64886475e-01,\n",
      "        8.15496922e-01]], shape=(2719, 5), dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "# Create comparison summary\n",
    "summary_data = []\n",
    "for result in all_results:\n",
    "    summary_data.append({\n",
    "        'Model': result['model_name'],\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'F1-Weighted': result['f1_weighted'],\n",
    "        'F1-Macro': result['f1_macro'],\n",
    "        'AUC Score': result['auc_score']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(all_results)\n",
    "#summary_df = summary_df.sort_values('F1-Weighted', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184dacc9-55cb-4bda-8bd1-3f46edca9327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "================================================================================\n",
      "                Model  Accuracy  F1-Weighted  F1-Macro  AUC Score\n",
      " Deep MLP with TF-IDF    0.6609       0.6851    0.4377     0.8637\n",
      "            CNN Model    0.5337       0.5904    0.3456     0.8626\n",
      "           LSTM Model    0.5094       0.5776    0.3517     0.8754\n",
      "      Hybrid CNN-LSTM    0.4678       0.5441    0.3173     0.8453\n",
      "BiLSTM with Attention    0.4546       0.5240    0.3190     0.8515\n",
      "    Transformer Model    0.2041       0.2376    0.1615     0.5741\n",
      "\n",
      "Best performing model: Deep MLP with TF-IDF\n",
      "Best F1-Weighted Score: 0.6851\n",
      "⚠️ Model Deep MLP with TF-IDF not found in trained models\n",
      "⚠️ Model LSTM Model not found in trained models\n",
      "⚠️ Model BiLSTM with Attention not found in trained models\n",
      "⚠️ Model CNN Model not found in trained models\n",
      "⚠️ Model Transformer Model not found in trained models\n",
      "✅ Saved API-ready Hybrid CNN-LSTM package to api_models\\hybrid_cnn-lstm\n",
      "\n",
      "All models saved in API-ready format.\n",
      "You can now deploy any model by copying its directory to your API server.\n",
      "All models and results saved. Results path: api_models\\data\\model_results_20250810_085116.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create comparison summary\n",
    "summary_data = []\n",
    "for result in all_results:\n",
    "    summary_data.append({\n",
    "        'Model': result['model_name'],\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'F1-Weighted': result['f1_weighted'],\n",
    "        'F1-Macro': result['f1_macro'],\n",
    "        'AUC Score': result['auc_score']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('F1-Weighted', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print('='*80)\n",
    "print(summary_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('data/model_comparison_summary.csv', index=False)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "metrics = ['Accuracy', 'F1-Weighted', 'F1-Macro', 'AUC Score']\n",
    "x = np.arange(len(summary_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i*width, summary_df[metric], width, label=metric, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Deep Learning Models Performance Comparison')\n",
    "plt.xticks(x + width*1.5, summary_df['Model'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('charts/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nBest performing model: {summary_df.iloc[0]['Model']}\")\n",
    "print(f\"Best F1-Weighted Score: {summary_df.iloc[0]['F1-Weighted']:.4f}\")\n",
    "\n",
    "# After training all models, save everything\n",
    "results_path = model_builder.save_all_models(all_results)\n",
    "print(f\"All models and results saved. Results path: {results_path}\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ee117-9983-4d02-a4de-a0e26e8aa5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
